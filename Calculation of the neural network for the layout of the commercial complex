-- Inputs (X1 to X12)

Columns X1 to X12 are the initial input data that describe various characteristics of the complexes. These data are gathered from information sources and are used as inputs for the neural network.

Hidden Layer 1

Each node in the first hidden layer is the weighted sum of inputs plus the bias corresponding to each node. Calculations for nodes in the first hidden layer are as follows:

\text{Hidden\_Layer1\_Node} = \sigma (w_1 \times X1 + w_2 \times X2 + \dots + w_{12} \times X12 + \text{Bias})

 represents the weight for each input.

 is the activation function (typically the sigmoid or ReLU function).


Hidden Layer 2

Each node in the second hidden layer is also computed as the weighted sum of outputs from nodes in the first hidden layer, plus the corresponding bias:

\text{Hidden\_Layer2\_Node} = \sigma (w_1 \times \text{Hidden\_Layer1\_Node1} + w_2 \times \text{Hidden\_Layer1\_Node2} + \dots + \text{Bias})

Outputs (Y)

The Y column (final output) is a combination of nodes from the second hidden layer, weighted and biased to ultimately determine the layout type of the complex:

\text{Output\_Y} = \sigma (w_1 \times \text{Hidden\_Layer2\_Node1} + w_2 \times \text{Hidden\_Layer2\_Node2} + \dots + \text{Bias})

Additional Notes in the File

In the updated Excel file, these explanations are added as a legend at the bottom of the table to clarify the calculation method for each column.


برای ارائه توضیحات محاسباتی هر سلول در شبکه عصبی موجود در فایل اکسل
ورودی‌ها (X1 تا X12)
ستون‌های X1 تا X12 داده‌های ورودی اولیه‌ای هستند که ویژگی‌های مختلف مجتمع‌ها را توصیف می‌کنند. این داده‌ها از منابع اطلاعاتی جمع‌آوری شده و به عنوان ورودی‌های شبکه عصبی مورد استفاده قرار می‌گیرند.
لایه مخفی اول (Hidden Layer 1)
هر نود در لایه مخفی اول حاصل جمع وزن‌دار ورودی‌ها به همراه بایاس مربوط به هر نود است. محاسبات برای نودهای لایه مخفی اول به صورت زیر انجام می‌شود:
\text{Hidden\_Layer1\_Node} = \sigma (w_1 \times X1 + w_2 \times X2 + \dots + w_{12} \times X12 + \text{Bias})
که در آن:
 وزن مربوط به ورودی  است.
 تابع فعال‌سازی است (معمولاً از تابع سیگموید یا ReLU استفاده می‌شود).
لایه مخفی دوم (Hidden Layer 2)
هر نود در لایه مخفی دوم نیز به صورت حاصل جمع وزن‌دار خروجی نودهای لایه مخفی اول و بایاس مربوطه محاسبه می‌شود:

\text{Hidden\_Layer2\_Node} = \sigma (w_1 \times \text{Hidden\_Layer1\_Node1} + w_2 \times \text{Hidden\_Layer1\_Node2} + \dots + \text{Bias})
در این مرحله هم از تابع فعال‌سازی است-- Inputs (X1 to X12)

Columns X1 to X12 are the initial input data that describe various characteristics of the complexes. These data are gathered from information sources and are used as inputs for the neural network.

Hidden Layer 1

Each node in the first hidden layer is the weighted sum of inputs plus the bias corresponding to each node. Calculations for nodes in the first hidden layer are as follows:

\text{Hidden\_Layer1\_Node} = \sigma (w_1 \times X1 + w_2 \times X2 + \dots + w_{12} \times X12 + \text{Bias})

 represents the weight for each input.

 is the activation function (typically the sigmoid or ReLU function).


Hidden Layer 2

Each node in the second hidden layer is also computed as the weighted sum of outputs from nodes in the first hidden layer, plus the corresponding bias:

\text{Hidden\_Layer2\_Node} = \sigma (w_1 \times \text{Hidden\_Layer1\_Node1} + w_2 \times \text{Hidden\_Layer1\_Node2} + \dots + \text{Bias})

Outputs (Y)

The Y column (final output) is a combination of nodes from the second hidden layer, weighted and biased to ultimately determine the layout type of the complex:

\text{Output\_Y} = \sigma (w_1 \times \text{Hidden\_Layer2\_Node1} + w_2 \times \text{Hidden\_Layer2\_Node2} + \dots + \text{Bias})

Additional Notes in the File

In the updated Excel file, these explanations are added as a legend at the bottom of the table to clarify the calculation method for each column.


برای ارائه توضیحات محاسباتی هر سلول در شبکه عصبی موجود در فایل اکسل
ورودی‌ها (X1 تا X12)
ستون‌های X1 تا X12 داده‌های ورودی اولیه‌ای هستند که ویژگی‌های مختلف مجتمع‌ها را توصیف می‌کنند. این داده‌ها از منابع اطلاعاتی جمع‌آوری شده و به عنوان ورودی‌های شبکه عصبی مورد استفاده قرار می‌گیرند.
لایه مخفی اول (Hidden Layer 1)
هر نود در لایه مخفی اول حاصل جمع وزن‌دار ورودی‌ها به همراه بایاس مربوط به هر نود است. محاسبات برای نودهای لایه مخفی اول به صورت زیر انجام می‌شود:
\text{Hidden\_Layer1\_Node} = \sigma (w_1 \times X1 + w_2 \times X2 + \dots + w_{12} \times X12 + \text{Bias})
که در آن:
 وزن مربوط به ورودی  است.
 تابع فعال‌سازی است (معمولاً از تابع سیگموید یا ReLU استفاده می‌شود).
لایه مخفی دوم (Hidden Layer 2)
هر نود در لایه مخفی دوم نیز به صورت حاصل جمع وزن‌دار خروجی نودهای لایه مخفی اول و بایاس مربوطه محاسبه می‌شود:

\text{Hidden\_Layer2\_Node} = \sigma (w_1 \times \text{Hidden\_Layer1\_Node1} + w_2 \times \text{Hidden\_Layer1\_Node2} + \dots + \text{Bias})
در این مرحله هم از تابع فعال‌سازی استفاده می‌شود.
خروجی‌ها (Y)
ستون Y (خروجی نهایی) ترکیبی از نودهای لایه مخفی دوم است که وزن‌دهی و بایاس آن‌ها اعمال شده و در نهایت به نوع چیدمان مجتمع می‌انجامد:
\text{Output\_Y} = \sigma (w_1 \times \text{Hidden\_Layer2\_Node1} + w_2 \times \text{Hidden\_Layer2\_Node2} + \dots + \text{Bias})

در اینجا نیز تابع فعال‌سازی به کار می‌رود تا اعداد به مقادیر خروجی متناسب تبدیل شوند.

توضیحات اضافی در فایل
در فایل اکسل به‌روز شده، این توضیحات به‌صورت لجند در پایین جدول اضافه شده تا نحوه محاسبه هر ستون دقیقاً مشخص باشد.
فاده می‌شود.
خروجی‌ها (Y)
ستون Y (خروجی نهایی) ترکیبی از نودهای لایه مخفی دوم است که وزن‌دهی و بایاس آن‌ها اعمال شده و در نهایت به نوع چیدمان مجتمع می‌انجامد:
\text{Output\_Y} = \sigma (w_1 \times \text{Hidden\_Layer2\_Node1} + w_2 \times \text{Hidden\_Layer2\_Node2} + \dots + \text{Bias})

در اینجا نیز تابع فعال‌سازی به کار می‌رود تا اعداد به مقادیر خروجی متناسب تبدیل شوند.

توضیحات اضافی در فایل
در فایل اکسل به‌روز شده، این توضیحات به‌صورت لجند در پایین جدول اضافه شده تا نحوه محاسبه هر ستون دقیقاً مشخص باشد.
