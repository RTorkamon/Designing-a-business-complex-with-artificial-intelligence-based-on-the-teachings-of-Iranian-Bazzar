})1({^x + b})1({^W = })1({^z
] )})1({^text{ReLU}(z\ = })1({^a
الیه مخفی اول تا الیه مخفی دوم:
})2({^b + })1({^a})2({^W = })2({^z
] )})2({^text{ReLU}(z\ =
^a})3({^W = })3({^z
 ] )})3({^hat{y} = \text{softmax}(z\
احتمال هر کدام از 8 چیدمان مختلف را ارائه میدهد.
کامپایل مدل: از بهینه ساز Adam و تابع زیان crossentropy_categorical برای چندکالسه بودن خروجی استفاده 
شده است.
کد کامل پایتون برای طراحی و آموزش یک مدل شبکه عصبی با استفاده از TensorFlow ارائه شده است. این مدل 
شامل دو الیه مخفی با تابع فعالسازی ReLU و یک الیه خروجی با تابع Softmax است.
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import numpy as np
# دادههای فرضی: 25 نمونه، هر نمونه 12 ویژگی دارد
ورودی ویژگیهای( # 12 ,25(X = np.random.rand
خروجی دسته بندی Y = np.random.randint(0, 8, size=(25,)) # 8
# نرمالسازی دادههای ورودی
)(scaler = MinMaxScaler
X_scaled = scaler.fit_transform(X)
# تقسیم دادهها به مجموعههای آموزشی و آزمایشی
X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, 
random_state=42)
# تبدیل برچسبها به کدگذاری یک گرمی )encoding hot-one)
Y_train_one_hot = tf.keras.utils.to_categorical(Y_train, num_classes=8)
Y_test_one_hot = tf.keras.utils.to_categorical(Y_test, num_classes=8)
# ساختار شبکه عصبی
[(model = tf.keras.Sequential
نورون 8 با اول مخفی الیه, # tf.keras.layers.Dense(8, activation='relu', input_shape=(12,)) 
نورون 6 با دوم مخفی الیه, # tf.keras.layers.Dense(6, activation='relu') 
 نورون 8 با خروجی الیه # tf.keras.layers.Dense(8, activation='softmax') 
)Softmax(
)]
# کامپایل مدل
,'model.compile(optimizer='adam
,'loss='categorical_crossentropy 
)metrics=['accuracy'] 
# آموزش مدل
history = model.fit(X_train, Y_train_one_hot, epochs=50, batch_size=8, 
validation_split=0.1)
# ارزیابی مدل
test_loss, test_acc = model.evaluate(X_test, Y_test_one_hot)
print(f"Test Accuracy: {test_acc:.4f}")
# پیشبینی نمونه های جدید
predictions = model.predict(X_test)
)metrics=['accuracy'] 
# آموزش مدل
histor})1({^x + b})1({^W = })1({^z
] )})1({^text{ReLU}(z\ = })1({^a
الیه مخفی اول تا الیه مخفی دوم:
})2({^b + })1({^a})2({^W = })2({^z
] )})2({^text{ReLU}(z\ =
^a})3({^W = })3({^z
 ] )})3({^hat{y} = \text{softmax}(z\
احتمال هر کدام از 8 چیدمان مختلف را ارائه میدهد.
کامپایل مدل: از بهینه ساز Adam و تابع زیان crossentropy_categorical برای چندکالسه بودن خروجی استفاده 
شده است.
کد کامل پایتون برای طراحی و آموزش یک مدل شبکه عصبی با استفاده از TensorFlow ارائه شده است. این مدل 
شامل دو الیه مخفی با تابع فعالسازی ReLU و یک الیه خروجی با تابع Softmax است.
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import numpy as np
# دادههای فرضی: 25 نمونه، هر نمونه 12 ویژگی دارد
ورودی ویژگیهای( # 12 ,25(X = np.random.rand
خروجی دسته بندی Y = np.random.randint(0, 8, size=(25,)) # 8
# نرمالسازی دادههای ورودی
)(scaler = MinMaxScaler
X_scaled = scaler.fit_transform(X)
# تقسیم دادهها به مجموعههای آموزشی و آزمایشی
X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, 
random_state=42)
# تبدیل برچسبها به کدگذاری یک گرمی )encoding hot-one)
Y_train_one_hot = tf.keras.utils.to_categorical(Y_train, num_classes=8)
Y_test_one_hot = tf.keras.utils.to_categorical(Y_test, num_classes=8)
# ساختار شبکه عصبی
[(model = tf.keras.Sequential
نورون 8 با اول مخفی الیه, # tf.keras.layers.Dense(8, activation='relu', input_shape=(12,)) 
نورون 6 با دوم مخفی الیه, # tf.keras.layers.Dense(6, activation='relu') 
 نورون 8 با خروجی الیه # tf.keras.layers.Dense(8, activation='softmax') 
)Softmax(
)]
# کامپایل مدل
,'model.compile(optimizer='adam
,'loss='categorical_crossentropy 
)metrics=['accuracy'] 
# آموزش مدل
history = model.fit(X_train, Y_train_one_hot, epochs=50, batch_size=8, 
validation_split=0.1)
# ارزیابی مدل
test_loss, test_acc = model.evaluate(X_test, Y_test_one_hot)
print(f"Test Accuracy: {test_acc:.4f}")
# پیشبینی نمونه های جدید
predictions = model.predict(X_test)
)metrics=['accuracy'] 
# آموزش مدل
history = model.fit(X_train, Y_train_one_hot, epochs=50, batch_size=8, 
validation_split=0.1)
# ارزیابی مدل
test_loss, test_acc = model.evaluate(X_test, Y_test_one_hot)
print(f"Test Accuracy: {test_acc:.4f}")
# پیشبینی نمونه های جدید
predictions = model.predict(X_test
L = - })1({^x + b})1({^W = })1({^z
] )})1({^text{ReLU}(z\ = })1({^a
الیه مخفی اول تا الیه مخفی دوم:
})2({^b + })1({^a})2({^W = })2({^z
] )})2({^text{ReLU}(z\ =
^a})3({^W = })3({^z
 ] )})3({^hat{y} = \text{softmax}(z\
احتمال هر کدام از 8 چیدمان مختلف را ارائه میدهد.
کامپایل مدل: از بهینه ساز Adam و تابع زیان crossentropy_categorical برای چندکالسه بودن خروجی استفاده 
شده است.
کد کامل پایتون برای طراحی و آموزش یک مدل شبکه عصبی با استفاده از TensorFlow ارائه شده است. این مدل 
شامل دو الیه مخفی با تابع فعالسازی ReLU و یک الیه خروجی با تابع Softmax است.
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import numpy as np
# دادههای فرضی: 25 نمونه، هر نمونه 12 ویژگی دارد
ورودی ویژگیهای( # 12 ,25(X = np.random.rand
خروجی دسته بندی Y = np.random.randint(0, 8, size=(25,)) # 8
# نرمالسازی دادههای ورودی
)(scaler = MinMaxScaler
X_scaled = scaler.fit_transform(X)
# تقسیم دادهها به مجموعههای آموزشی و آزمایشی
X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, 
random_state=42)
# تبدیل برچسبها به کدگذاری یک گرمی )encoding hot-one)
Y_train_one_hot = tf.keras.utils.to_categorical(Y_train, num_classes=8)
Y_test_one_hot = tf.keras.utils.to_categorical(Y_test, num_classes=8)
# ساختار شبکه عصبی
[(model = tf.keras.Sequential
نورون 8 با اول مخفی الیه, # tf.keras.layers.Dense(8, activation='relu', input_shape=(12,)) 
نورون 6 با دوم مخفی الیه, # tf.keras.layers.Dense(6, activation='relu') 
 نورون 8 با خروجی الیه # tf.keras.layers.Dense(8, activation='softmax') 
)Softmax(
)]
# کامپایل مدل
,'model.compile(optimizer='adam
,'loss='categorical_crossentropy 
)metrics=['accuracy'] 
# آموزش مدل
history = model.fit(X_train, Y_train_one_hot, epochs=50, batch_size=8, 
validation_split=0.1)
# ارزیابی مدل
test_loss, test_acc = model.evaluate(X_test, Y_test_one_hot)
print(f"Test Accuracy: {test_acc:.4f}")
# پیشبینی نمونه های جدید
predictions = model.predict(X_test)
)metrics=['accuracy'] 
# آموزش مدل
histor})1({^x + b})1({^W = })1({^z
] )})1({^text{ReLU}(z\ = })1({^a
الیه مخفی اول تا الیه مخفی دوم:
})2({^b + })1({^a})2({^W = })2({^z
] )})2({^text{ReLU}(z\ =
^a})3({^W = })3({^z
 ] )})3({^hat{y} = \text{softmax}(z\
احتمال هر کدام از 8 چیدمان مختلف را ارائه میدهد.
کامپایل مدل: از بهینه ساز Adam و تابع زیان crossentropy_categorical برای چندکالسه بودن خروجی استفاده 
شده است.
کد کامل پایتون برای طراحی و آموزش یک مدل شبکه عصبی با استفاده از TensorFlow ارائه شده است. این مدل 
شامل دو الیه مخفی با تابع فعالسازی ReLU و یک الیه خروجی با تابع Softmax است.
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import numpy as np
# دادههای فرضی: 25 نمونه، هر نمونه 12 ویژگی دارد
ورودی ویژگیهای( # 12 ,25(X = np.random.rand
خروجی دسته بندی Y = np.random.randint(0, 8, size=(25,)) # 8
# نرمالسازی دادههای ورودی
)(scaler = MinMaxScaler
X_scaled = scaler.fit_transform(X)
# تقسیم دادهها به مجموعههای آموزشی و آزمایشی
X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, 
random_state=42)
# تبدیل برچسبها به کدگذاری یک گرمی )encoding hot-one)
Y_train_one_hot = tf.keras.utils.to_categorical(Y_train, num_classes=8)
Y_test_one_hot = tf.keras.utils.to_categorical(Y_test, num_classes=8)
# ساختار شبکه عصبی
[(model = tf.keras.Sequential
نورون 8 با اول مخفی الیه, # tf.keras.layers.Dense(8, activation='relu', input_shape=(12,)) 
نورون 6 با دوم مخفی الیه, # tf.keras.layers.Dense(6, activation='relu') 
 نورون 8 با خروجی الیه # tf.keras.layers.Dense(8, activation='softmax') 
)Softmax(
)]
# کامپایل مدل
,'model.compile(optimizer='adam
,'loss='categorical_crossentropy 
)metrics=['accuracy'] 
# آموزش مدل
history = model.fit(X_train, Y_train_one_hot, epochs=50, batch_size=8, 
validation_split=0.1)
# ارزیابی مدل
test_loss, test_acc = model.evaluate(X_test, Y_test_one_hot)
print(f"Test Accuracy: {test_acc:.4f}")
# پیشبینی نمونه های جدید
predictions = model.predict(X_test)
)metrics=['accuracy'] 
# آموزش مدل
history = model.fit(X_train, Y_train_one_hot, epochs=50, batch_size=8, 
validation_split=0.1)
# ارزیابی مدل
test_loss, test_acc = model.evaluate(X_test, Y_test_one_hot)
print(f"Test Accuracy: {test_acc:.4f}")
# پیشبینی نمونه های جدید
predictions = model.predict(X_test
L = - \sum_{i} y_i \log(\hat{y}_i)
y = model.fit(X_train, Y_train_one_hot, epochs=50, batch_size=8, 
validation_split=0.1)
# ارزیابی مدل
test_loss, test_acc = model.evaluate(X_test, Y_test_one_hot)
print(f"Test Accuracy: {test_acc:.4f}")
# پیشبینی نمونه های جدید
predictions = model.predict(X_test
L = - \sum_{i} y_i \log(\hat{y}_i)
\sum_{i} y_i \log(\hat{y}_i)
y = model.fit(X_train, Y_train_one_hot, epochs=50, batch_size=8, 
validation_split=0.1)
# ارزیابی مدل
test_loss, test_acc = model.evaluate(X_test, Y_test_one_hot)
print(f"Test Accuracy: {test_acc:.4f}")
# پیشبینی نمونه های جدید
predictions = model.predict(X_test
L = - \sum_{i} y_i \log(\hat{y}_i)
